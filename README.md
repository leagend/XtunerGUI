<div align="center">
  <img src="https://github.com/scchy/XtunerGUI/assets/108343727/93376dab-fae8-46f8-8956-58465cbbcb98" width="1000"/>
  <br /><br />
                
[![GitHub Repo stars](https://img.shields.io/github/stars/scchy/XtunerGUI?style=social)](https://github.com/scchy/XtunerGUI/stargazers)              

<div align="left">

# 1. 项目背景

XTuner是由InternLM团队开发的一个高效、灵活且全能的轻量化大模型微调工具库。其主要用于多种大型语言模型的高效微调，包括大语言模型InternLM和多模态图文模型LLaVa。XTuner不仅提供了丰富的模型、数据集、数据管道和算法支持，还配备了现成的配置文件和快速入门指南，使得用户能够便捷地进行模型微调和部署。总体来看，XTuner为大型语言模型的微调提供了一个高效、全面且用户友好的解决方案，适用于追求性能优化和定制化的开发者和研究者。

 虽然XTuner已经简化了大量微调中的步骤，但由于对于0基础的小白而言，还是具有一定的技术门槛。因此，借由InternLM官方推出的大模型实战训练营的机会，我们小组成员有幸与XTuner官方技术团队合作，在参考了  [LLaMA-Factory](https://github.com/hiyouga/LLaMA-Factory) 的基础上，根据XTuner的特性进行修改完善，从而完成了基于Gradio的XTuner可视化的界面设计。
此项目旨在为基础知识较弱的初学者提供便捷的微调解决方案，使他们能够通过简单的点击来尝试对模型进行微调。该界面能够实时展示训练信息和训练结果，并支持用户对微调后的模型与原始模型进行对比测试。此外，除了支持官方提供的模型和数据集之外，高级用户还可以上传自己的模型和数据集进行微调。这种自定义模型的功能不仅有助于初学者在已经微调过的模型基础上进行进一步的学习和探索，也大大增强了该界面的实用性和灵活性。

# 2. 项目成员介绍
XTuner GUI项目得到了XTuner官方的支持，因此除了浦语实战训练营里的四位成员外，还包括了两名XTuner专业的开发人员cwh及pppppM。下面是对各个成员的贡献进行介绍，感谢大家一个多月以来的辛勤付出！也感谢书生.浦语官方为我们所提供课程以及算力支持！相信AI Lab将持续做大做强，成为中国数一数二的开源社区！
![image](https://github.com/scchy/XtunerGUI/assets/108343727/f10cabd8-c027-4fd9-95da-15c5f351f79d)

2.1 Xtuner GUI团队成员包括
- Jianfeng777 – 负责整体前端开发、任务策划及文案撰写
- Scchy – 负责整体后端开发及规划
- L241025097 – 负责模型训练终端可视化
- Semple030228 – 负责模型转换及整合部分

2.2 XTuner开发人员
- HIT-cwh - 负责mmengine相关内容设置及配置文件生成，模型和数据集检查等开发工作
- pppppM - 提供XTuner方面专业的指导意见

# 3. 快速启动（仅支持Linux系统）
首先我们需要创建一个新的虚拟环境，并将GitHub的内容克隆到本地。

```bash
conda create -n XtunerGUI python=3.10 -y
conda activate XtunerGUI
git clone https://github.com/scchy/XtunerGUI.git
```

然后我们需要进入仓库的内部并安装运行XTunerGUI所需要的包（假如安装速度过慢请使用清华源镜像）。

```bash
cd XtunerGUI
pip install -r requirements.txt
```

经过一段时间的安装后，我们就可以启动`app.py`文件进入我们创建的界面。

```bash
python app.py
```

# 4. UI界面介绍
本页面共分为六部分，内容涵盖了大语言模型中所有基础的步骤（具体可看下图），下面我将一步步带领大家了解页面的布局以及具体的使用方式。此外，我们可以在OpenXLab里查看完整的页面细节（[链接](https://openxlab.org.cn/apps/detail/Scchy/XtunerFactory)）。

## 4.1 本地路径设置
![image](https://github.com/scchy/XtunerGUI/assets/108343727/e0d540bb-8a7b-4c67-a379-f5aeac8cbd90)

第一步，我们先要输入两个本地的路径。一个是整体文件保存的位置，另外一个是模型和数据集下载保存的位置。对于文件保存路径（customer_path）而言，在该路径下将保存配置文件、所有的训练过程文件（权重文件、训练日志等）及模型转换后的内容。那对于模型数据集文件路径（download_cache）而言，该路径下将保存在UI界面中下载的模型和数据集文件。在对路径进行修改后切记要点击确认路径按钮哦！
## 4.2 微调方法、模型、数据集设置
![image](https://github.com/scchy/XtunerGUI/assets/108343727/428b39c3-c1cd-4eca-90b1-2cfc79d8c6cc)

第二步，在这里我们需要选择微调的方法，目前已支持QLoRA、LoRA和全量微调（full）三种方法，大家可以根据自己的硬件情况和实际任务需求进行选择。另外我们也支持大量的官方数据集和模型，通过点击下方下载按钮即可自动从Modelscope、Huggingface和OpenXLab三个平台进行下载。假如发现下载错模型或者数据集也可点击取消下载工作，下载任务取消后将删除已下载的内容，从而减少内存的占用。
![image](https://github.com/scchy/XtunerGUI/assets/108343727/c5bf98aa-3cc3-4dbd-b33f-0fe0f6605fb9)

另外我们还支持大家上传自定义的模型或者数据集。
- 对于自定义的模型，我们可以通过上传本地的路径，并且点击按钮即可检查模型是否可用及对模型提示词模版的匹配（在UI界面点击下载按钮下载的官方模型会自动进行提示词模版匹配），不同的模型会有其独特的提示词模版，更多详细信息可以进入UI界面中查看。
- 对于自定义的数据集，我们目前仅支持OpenAI的数据集格式（最通用的数据集格式）。在UI界面中也展示了OpenAI数据集的格式，大家可以通过各类的大语言模型（比如说ChatGPT）对自己的数据集进行格式的更改。在将数据集格式转为OpenAI格式后，我们可以通过输入本地数据集路径或者将文件在gradio的文件框上上传。在完成数据集文件上传后，还可点击按钮检查数据集是否符合规定。
## 4.3 微调参数设置
第三步，在微调参数设置处，我们将所有的参数分为了基础参数和进阶参数两部分。我们根据微调方法的不同设置了几套默认的参数模版，一般情况下大家可以直接使用该参数进行微调即可。
![image](https://github.com/scchy/XtunerGUI/assets/108343727/d776dae4-cb02-4e12-a09f-f5187f79be55)

在基础参数部分是我们比较常用的参数，包括学习率、预热比、数据集最大长度、GPU数量、设备样本个数以及评估问题等等。值得一提的是我们可以自己设置多个评估问题，默认的评估问题是"请给我介绍五个上海景点"的中英文版，但是我们可以将其修改为我们所需要的问题，并且通过选择问题的数量可以增加在评估时候的问题（最多十个问题）。
![image](https://github.com/scchy/XtunerGUI/assets/108343727/048eb439-12d4-46a1-bff5-361d7641b3d3)

对于进阶参数而言，就是一些比较不常使用也不怎么需要修改的参数，比如说优化器的类型、权重衰减、梯度剪裁等。这些虽然会影响模型的效果，但是修改优化的难度比较大，大家在使用过程中除非有明确的修改目的，否则不建议大家进行更改。
在完成了参数的设置后，接下来就需要点击按钮生成配置文件了。配置文件的生成的模型训练的灵魂，模型的训练过程和方向都是基于配置文件里的内容进行。在这里配置文件的创建就是基于上面我们设置的内容。这里需要注意的是，假如大家同时在自定义数据集/模型以及在GUI界面下载了模型/数据集，这里默认以自定义的数据集/模型作为配置文件的模型/数据集的路径，因此大家在使用的过程中需要注意这一点。
## 4.4 微调模型训练
![image](https://github.com/scchy/XtunerGUI/assets/108343727/ed919fd9-3641-475c-b17a-7504f05fc502)

在完成配置文件后，我们就可以点击按钮启动模型训练工作。当然我们也可以点击按钮暂时中断我们的训练过程。当我们需要对中断的模型继续训练的时候，我们可以选择之前保存的权重并点击按钮继续训练。中断后续训是不会影响最终模型训练的效果的。
另外，在我们点击训练后，我们可以打开下面的终端界面查看训练的过程以及内容，这样我们就能够更好的监控整体的训练过程。假如训练效果过差，我们也能够及时进行模型训练的中断，以免浪费无谓的时间。
## 4.5 微调结果展示
![image](https://github.com/scchy/XtunerGUI/assets/108343727/90f24f77-31c6-40c3-aec6-2958f6c75450)

在模型微调进程结束后，我们可以点击下方按钮生成一些关键内容的展示。包括说损失函数的的变化图、学习率在训练过程中的变化图以及不同权重文件下测试问题。这样我们就既能够看到模型训练过程的变化，也能够通过测试问题的对比来看到模型是否过拟合，从而找到最优的权重文件进行模型测试及部署。
## 4.6 微调模型转化及测试
![image](https://github.com/scchy/XtunerGUI/assets/108343727/31a0a9fe-58f2-4ce4-8fa1-1cc7dc84de55)

在我们通过微调结果展示找到效果最好的模型权重文件后，我们还需要将我们的模型转化为常见的HuggingFace格式。对于LoRA或者QLoRA方式微调出来的模型还需要与原模型进行整合。在这里我们合并了这两部分，我们会基于大家第二步选择的微调方法进行调整。具体的操作就是我们需要在下拉列表中找到对应的权重文件后，点击模型转换按钮即可。
![image](https://github.com/scchy/XtunerGUI/assets/108343727/f7e5356e-ceb3-4baa-a430-68668514f383)

在模型转换后，我们就可以进行对话的测试。在左边可以展示原来底座模型的效果，而右边展示的是微调后模型的效果。我们只需要选择合适的模型推理参数，点击模型启动即可进行对话。我们可以通过原模型和微调后模型的对比查看微调的实际效果。

以下是我们录制的一个简短使用视频（[B站](https://www.bilibili.com/video/BV1av42117yT/?spm_id_from=333.999.0.0)），大家可以通过视频来作更进一步的了解。

以上就是页面的一个基本的介绍，假如大家想单纯的使用的话就可以马上开始上手啦！但是假如大家希望对我们设计的思路以及原理有更深刻的认识的话，那就继续往下看吧！
下面的部分我们将谈谈XTuner GUI背后的XTuner的运作原理，从而能够更深一层次的了解XTuner GUI的实现原理。正所谓知其然还需要知其所以然，假如我们能够真正的通过XTuner整体的结构设计以及指令，那我们就能更好的理解XTuner GUI项目的运行机理。

# 5. XTuner流程介绍
对于XTuner的基本操作，我们可以通过以下这张图，简单的了解一下。高清图片链接请点[击此位置](https://www.figma.com/file/0SVTWhnGxbY7ADy2UEluCR/XTuner-Flow?type=whiteboard&node-id=0%3A1&t=bzZP6fCSAuBj2uon-1)。

![image](https://github.com/scchy/XtunerGUI/assets/108343727/50dd5543-1f65-4984-a5a2-35a045e1f5c6)

可以看到，整个工作流程分为以下四个步骤（具体各个步骤的调用代码可参考下图）：
![image](https://github.com/scchy/XtunerGUI/assets/108343727/f6a7722a-aca1-43cf-81d4-3e3d9de37a9a)

## 5.1 数据采集及格式转换
![image](https://github.com/scchy/XtunerGUI/assets/108343727/15384b89-aea9-4049-8866-f407ab93d314)

- 首先，根据任务的不同，我们需要明确微调目标，进行数据采集，并将数据转换为 XTuner 所支持的格式类型。这部分需要大家自行完成，当然我们假如只是体验的话仅需要使用官方支持的数据集即可。
- 然后我们还需要根据自己的硬件条件选择合适的微调方法和合适的基座模型。不同的基座模型对显存的需求都不太一样，模型参数越大，微调所需要显存就越多。而在微调方法中，对显存需求最小的就是QLoRA（最少8GB即可运行），而显存需求最大的则是全量微调。
## 5.2 配置文件的创建
![image](https://github.com/scchy/XtunerGUI/assets/108343727/310323ad-def0-4748-b2e5-fe8e1c808344)

- 首先，我们可以通过执行 xtuner list-cfg 命令列出所有配置文件。
- 通过上面选择的微调方法和基座模型找到合适的配置文件，并使用 xtuner copy-cfg ${CONFIG_NAME} ${SAVE_PATH} 命令复制到本地端。
- 复制完成后还需要根据自己的需求修改配置文件以更新模型路径和数据集路径。
- 特定时候还需要调整模型参数和配置，更改 load_dataset 函数和 dataset_map_fn 函数。并根据模型选择合适的 prompt_template。
## 5.3 模型训练
![image](https://github.com/scchy/XtunerGUI/assets/108343727/1b568d6a-5da1-493e-826c-f474b7a00db0)

- 修改配置文件后，我就可以使用 xtuner train 命令启动训练。
- 除此之外我们还可以设置特定参数优化训练，如启用 deepspeed，以及设置训练文件的保存路径。
- 假如意外的中断了训练，还可以通过加上--resume {checkpoint_path}的方式进行模型续训。具体可看下面的指令详解。
## 5.4 模型转换、测试及部署
![image](https://github.com/scchy/XtunerGUI/assets/108343727/ba34bad6-f771-40aa-a82c-f53096c71841)

- 在完成训练后，找到对应的训练文件并执行 `xtuner convert pth_to_hf` 命令，就可以将转换模型格式为 `huggingface` 格式。
- 对于LoRA类的模型而言，则需要执行 `xtuner convert merge` 命令将 `adapter` 层与原模型进行合并。
- 转换完成后，我们就可以以转换后的文件路径并使用 `xtuner chat` 命令启动模型进行性能测试。
- 除此之外，我们还可以在安装 `LMDeploy` 后通过 `python -m lmdeploy.pytorch.chat` 命令进行模型部署，即使用TurboMind进行推理。

以上就是关于XTuner项目的一些基础功能及指令的展示，下面我将通过XTuner GUI整体的逻辑图来深入的剖析我们在设计原型过程中的思路和对现有流程的优化点。
# 6. XTuner GUI设计思路介绍
那对于XTuner GUI而言，我们将其分为了六个部分路径设置、模型数据集微调方法设置、相关参数设置、模型训练、训练结果展示、模型转换及测试部分。之所以这样进行设计，主要目的还是希望作为一个小白可以先抛开一系列的专业知识，能够真真正正的先将模型跑起来看到效果后，再一步步的进行研究到底每一步的原理是什么。想当年我学习OpenMMLab相关的算法库，例如MMDetection和MMSegementation，我最开始的时候也就是去找到一些数据集然后跑起来，然后再慢慢研究怎么优化，整体运行逻辑。同样的，虽然XTuner的门槛已经非常低了，但是我希望能够把这个门槛能够降得更低，能够让更多人能够无痛上手。
那真正让用户无痛上手，那就必须要砍掉让他们思考的部分。比如说在原生的XTuner里面，我们还需要自己下载模型数据集，还需要找到合适的配置文件，还需要我们自己找到对应的文件夹进行转换等等，这些通通都不再需要，我们只需要通过点击按钮、选择下拉框的内容或者说调整一下参数就可以将模型跑起来了，并且最后也将整体的对话测试也是直接输入文本即可同时与原模型进行对话，这些都是我们希望能够最小化大家跑起模型的难度，能够真正打开大模型微调的大门。
除了对0基础的小白进行支持以外，我们对拥有一定使用经验的人也作出了考量。首先就是增加了自定义模型和自定义数据集两部分，那对于想要对自己的数据集或者模型微调的人就能够节省真正进入文件修改的时间。其次是提供了大量可修改的参数让大家进行选择。这些对于一个拥有一定经验的“炼丹师”而言，无疑是非常有意义的。
那对于大师而言，尤其是需要训练多模态模型的人，这里其实我们就没有做过多的特定支持。主要原因是这部分人群的代码能力和调试能力非常强，无论是使用原生的XTuner或者其他的微调工具都会得心应手，不需要过多在这些细节上进行可视化的展示。总的来说，我们所针对的人群其实更多是哪些0基础的小白以及有一定经验的炼丹师，通过使用这样一个工具能够更好的完成他们的工作。
那对于XTuner GUI而言，我同样也是制作了一个逻辑图来展示整体的运行思路（高清图片链接请[点击此位置](https://www.figma.com/file/wFN0wMlknYyzV3ZMCihnPC/XTuner-GUI-Flow?type=whiteboard&t=ch8xUYvYdXnoWGNX-1)）。

下面将一步步的解释整体的架构，并说明相比于原生的XTuner，我们作出了哪些的调整以及设计时的思路：

## 6.1 路径设置

<p align="center">
  <img src="https://github.com/scchy/XtunerGUI/assets/108343727/3dde057d-b0cb-4d06-8cda-3047cdfef7c2" alt="image" style="width: 48%;">
  <img src="https://github.com/scchy/XtunerGUI/assets/108343727/74e028d9-c34b-4b5c-95a8-00ee9c8a0f18" alt="image" style="width: 48%;">
</p>

首先我们可以看到我们需要传入的是文件保存路径及模型数据集文件保存路径。对于文件保存路径（customer_path）而言，在该路径下将保存配置文件、所有的训练过程文件（权重文件、训练日志等）及模型转换后的内容。那对于模型数据集文件路径（download_cache）而言，该路径下将保存在UI界面中下载的模型和数据集文件。
其实在初版的设计当中，这一部分其实是没有被添加进去的，但是后面我们发现下载的模型和数据集文件都可能会相对比较大，再加上后面微调后的文件可能会撑爆内存，因此我们决定将两者分开，用户可以自行选择合适的路径进行保存，这样就可以降低内存的压力。当然对于那些内存充足的人而言，仅需要按照默认的路径即可。
## 6.2 模型、数据集及微调方法设置
![image](https://github.com/scchy/XtunerGUI/assets/108343727/d3f26565-e445-4d0b-ab3f-031e855eaa05)

对于所有微调任务而言，第一步我们要考虑的都是说，我要微调什么模型，我要用什么数据集去微调这个模型，具体使用的微调方法是什么。这三个基本的步骤其实就拦住了很多的人，因为他们不知道去哪里找这些东西。即便是使用原生XTuner的时候，即便我们真的根据仓库中给出的快速开始将模型跑起来，但是我们还是可能不太理解这一切是怎么执行的。并且，在XTuner仓库里已有的config文件其实并不包含所有的模型、数据集和微调方法的组合，因此对于那些想直接用但是找不到对应config文件的人们来说，可能就真的是从入门到放弃了，毕竟对于他们而言，修改一个类似的config然后调整里面对应的东西难度都太高了吗，真的能做下来也不是0基础的小白了。
基于以上的思考，我们所做的就是简化这一系列的流程。首先我们设置了下拉框来直接根据需求选择模型微调的方法。其次是对于在Huggingface、Modelscope和OpenXLab上已有的数据集和模型，我们提供下拉框让他们直接进行选择并能够点击按钮进行下载。下载完的模型也将自动保存在上面设置的模型数据集文件保存路径（download_cache）上。这样用户是真的知道自己要训练的是一个什么模型，用的是一个什么数据集，具体的微调方法是什么，而不是仅仅给他们一个config文件一个文件名去自己领悟。
其次对于进阶用户的自定义模型和数据集，那用户可以选择上传自己的模型然后使用官方的数据集，也可以使用官方的模型然后使用自己的数据集进行微调，这些都是可行的。并且无论是数据集还是模型，我们都增加了一个检查的机制，来帮助用户了解自己的模型和数据集是否存在问题，是否能够正常使用，那就避免了后续出现bug无法解决的问题。
那对于模型而言，还有一个很重要的步骤就是有一个与之相匹配的提示词模版。一般来说，用户上传自己的模型也不会说提供一套自己的提示词模版，真的能够训练出一个自己提示词模版的模型那也不是小白了。一般而言，这些用户自己上传的模型都是微调别的官方大模型实现的。基于这一层的思考，我们就决定了对于用户自定义上传的模型，我们不仅检查其是否可用，还找到其对应的提示词模版，这样用户也不需要再找到原模型的提示词模版然后放进去了，这就节省了他们不少的时间和精力。
## 6.3 相关参数设置
![image](https://github.com/scchy/XtunerGUI/assets/108343727/38181c97-6158-4ab4-8aad-af914344aab7)

那在准备好模型数据集了以后，其实我们最重要需要的就是模型和数据集的一个路径作为配置文件的一个重要参数。除此之外呢，其实我们还是需要对一些基本的超参数以及训练的一些参数进行设置，这样才能够生成一个好的pipeline用于实际的模型训练。
对于大部分的人而言，如何调整参数都是一件相对复杂且困难的事情，因此这里我们也是基于微调方法的不同配套了不同的超参数模版，这个在XTuner原生的config创建时就已经制定好的了，只不过没有公开而已。另外，在UI界面里，每个超参数我都是进行了基本的解释和介绍，以方便初学者对这些参数的含义进行了解。
除了默认的基本超参数设置，一些个性化的内容还需要我们自己进行设置，包括GPU的数量、是否启动Deepspeed优化等。基于以上提到的这些的参数我们就能够生成一份可用的配置文件，并存放在我们最开始设置的文件保存路径（customer_path），从而能够利用创建好的这个pipeline开始我们个性化的训练过程。
但是需要注意的是，这个配置文件生成的内容并不是我们平常在XTuner见到的一个config文件，而是一个具有同等效用的json文件，这里也需要感谢XTuner官方开发团队的cwh为我们提供的支持。
## 6.4 模型训练
![image](https://github.com/scchy/XtunerGUI/assets/108343727/12dc5e9d-df3a-4496-8466-8f691d27d269)

其实到了模型训练这个阶段，基本上就是程序自己运行的事情了。但是我们考虑到有可能会出现的情况是中途因为什么特殊原因训练被中断了，这个时候我们必须提供一个续训的选项让用户能够重新将模型跑起来。假如是重新拉起一个训练过程的话，训练的结果可能和预先结果不太一样，这样问题也蛮严重。因此我们就选择使用XTuner train里面提供的选项--resume来进行续训。
其实在原本的考虑当中，我希望做成的样子其实是可以想OpenMMLab里面的魔改。就比如说我在MMDetection里的模型Loss一直降不下去了，那我可能就会拿到最后一个epoch的权重文件，然后修改config文件把这个权重文件load进去，并且修改调高学习率等参数来尝试看看能不能好的效果。但是在大模型中，这种魔改的操作并不常见，并且也不是初学者需要考虑的内容，因此在这里也没有加上去了。但是未来要是有需求的话也可以把这部分内容加上去。
此外，在我们最初的设置里也没有加上终端界面展示部分的内容，但是我们考虑到的一点是：模型训练所要花费的时间太长了，假如用户就看着前端的界面在那转，但是不知道到底发生了什么，训练到了哪一步，自己设置的评估问题回复大概是什么样的话，那么这也是一件很煎熬的事情。因此我们也是增加了一个不断更新的终端界面，以展示训练过程的内容和状态。并且有实验证明说，假如用户能够看到进度条的话，那么整体的焦虑情绪就不会那么严重（除非一直卡在99%），因此后续我们也将根据iter的数量加上一个进度条来让用户看到整体的进度，从而降低他们等待的焦虑。
在训练的过程中会产生大量的文件，包括说模型的权重文件以及记载模型训练过程的log文件，这些文件都将保存在文件保存路径（customer_path）下。需要注意的是，我们可以通过调整epoch数量、每个n个iter保存一次权重文件以及只保留n个权重文件这类型的训练参数来进行调整实际的训练过程。这样就能够让用户能够自己决定到底训练怎么进行，从而给予了大家更多的自由度。
## 6.5 训练结果展示
![image](https://github.com/scchy/XtunerGUI/assets/108343727/7c451d8c-a84c-4ec5-8308-89bd582dedc0)

在训练完成后，我们其实可以通过查看损失值的变化图等内容来看看模型训练的成果如何。这里我主要希望能够让大家能够真正的看到自己训练的模型是否满足大致的要求，尤其是看到不同的权重文件对应自己设定的评估问题的答案。这个能够看到不同阶段下模型能够对评估问题产生的回复其实我认为非常重要，这个其实就等同于看到一个婴儿一岁到两岁到三岁到长大成人的变化过程。可能一开始模型微调的时候所得到的答案并不满意，到后面慢慢变得成熟，到最后过拟合可能就只能懂得回答一个问题，这样的变化过程可以让我们清晰的找到哪个iter下的权重文件是最好的，从而能够真正筛选出好的权重文件。
此外，单纯的看Loss看learning rate其实真的并不足够，因为这些都是一些数字而已，Loss太低你可能会觉得说肯定过拟合了，那Loss太高你可能说是不是没训练好。真正能够评判一个模型的好坏还是要通过真刀真枪的进行对话测试。那在对话测试的话一般我们也就只是对某几个问题进行测试，那假如我们把这些关键的核心的问题能够放在评估问题里，让模型在训练过程中回答并看到其中变化，这确实是能够节省不少的时间。模型的其他能力比如说上下文啊，连续回复等等的就交给最后的对话测试环节吧，仅仅筛选的话通过看设定的评估问题的答案其实完全足够了。
## 6.6 模型转换及测试
![image](https://github.com/scchy/XtunerGUI/assets/108343727/37b87354-7bf1-43e0-a222-3559d4096023)

在找到最好的模型权重文件后，由于训练过程生成的是Pytroch格式权重文件，因此我们在后续使用前需要将其转为huggingface格式。那对于Lora或Qlora方法训练出来的模型是额外的层（adapter），因此需要将其与原模型进行整合才能进行进一步操作，而全量微调仅需要进行整合工作即可。整合后的模型也将保存在文件保存路径（customer_path）当中。在XTuner里面，模型的转换和整合是被分开来的，但是由于在UI界面完成的都是指定的任务，因此我们可以把这两步组合起来，根据最初设定的微调方法进行判定，假如是QLoRA或者LoRA的话就使用转换+整合，假如是全量微调就只用转换即可。这样用户就不用再去找文件夹然后输入到终端进行设置，而是直接一键生成即可。
另外对于模型对话测试这一块，我们其实是希望能够让用户感受一下微调前模型和微调后的差别。主要就是在页面里将聊天框一分为二，一边是原模型一边是微调后的模型，那用户同时问一个问题的时候两个模型都能给你回复，并且你也能看到两者的差别。这样用户其实就能够真的感受到微调后到底是什么样的，这也帮助他们了解进一步改进的方向。那假若真的测试后对模型不满意，可以将转换后模型路径传入自定义模型中继续训练或者重新进行训练。然后重复这样一个流程即可。
# 7. 总结及展望
总的来说，我们在XTuner提供的基础功能基础上，增加了一些独有的内容，包括说绘制loss和learning rate的图表、提取每次评估问题的答案并保存、手动下载数据集和模型到本地使用等等。我们可以很自信的说，该界面目前已实现了基本的微调功能，并且能够有效的帮助新入门者快速上手并训练属于自己的模型。我们相信随着XTuner的流行，XTuner GUI也将能够受到更多的关注，并帮助更多的初级开发者快速上手模型的微调工作。
对于这个XTuner GUI项目而言，未来可能会朝着以下几个方向进行持续的发展：

- **完善XTuner GUI的功能**：由于我们只花费了一个多月，并且大家都并不是全职的进行开发，因此其中还有一些问题需要解决，包括说实时显示训练的损失值，显示训练的进度条等等。另外还有很重要的一个内容就是需要适配Windows系统，由于我们的开发都是在浦语所提供的开发机上所进行的，而开发机的环境是Linux系统，因此我们还需要对Windows系统以及MacOS系统作出适配的工作。
- **利用SCC及HTML等前端界面完善界面**：目前我们的前端开发完全依赖于Gradio，这主要是由于我作为一名外行的前端开发者仅仅只懂得Gradio的制作，因此后期可能还需要专门的前端开发人员对界面可能作进一步的设计，让整体更加美观。
- **接入模型部署功能**：由于微调好的模型转换后的格式为HuggingFace的，但是HuggingFace格式下的推理速度和模型文件大小可能都不满足实际项目需求，所以可能还是需要进行实际的落地部署工作。因此我们还需要与LMDeploy进行整合，完成包括模型本地部署以及模型api部署等工作。
- **打造类似于OpenAI的PlayGround**：为了降低Agent的使用门槛，我们预计将来也将推出类似于PlayGround的界面，届时可以像OpenAI一样实现Function call、Retrieval、Code Interpreter、Vision、Audio以及Video等多模态调用的平台。

以上就是XTuner GUI这个项目未来的计划，再次感谢所有人员对此的付出，也感谢星佬、米佬等书生.浦语官方人员的帮助和算力支持，未来我们会持续的推进这个计划，为更多新手的快速入门出自己的一份力，也为开源社区作出更多的贡献！
作为项目的主要负责人，完成这个任务并且参与其中我也觉得非常的有成就感。一方面，能够为开源社区提供一套方案是一件非常有意义的事情，另一方面，在这个项目的开展过程中也认识了很多为爱发电的大佬们，大家能够一起不断学习且进步。真心希望书生浦语开源社区的生态越来越好，为中国的开源社区建立一个良好的榜样！
假如认为XTuner和XTuner GUI真的有对你产生帮助的话，也希望能给我们Star呀，对于开源社区来说，多一个的Star就代表多一份的认可。正如那句歌词说的，假如人人都能贡献出一点爱，那么世界也将更加的美好～相信随着开源社区的繁荣，国内也能不再那么的浮躁，而是真的做一些推动人类发展的大事吧！


> **都看到这里了，不留下个Star是不是有点说不过去啦～那就动动手指点进下面的链接给我Star啦！**
> - **XTuner项目链接**：[https://github.com/InternLM/xtuner](https://github.com/InternLM/xtuner)
> - **XTuner GUI项目链接**：[https://github.com/scchy/XtunerGUI](https://github.com/scchy/XtunerGUI)
>
> **什么？还要给我fork？！那我就代表所有开发者对你感谢啦！好人一生平安！**

